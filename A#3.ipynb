{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "## FALL-99 A#3\n",
    "### Bahar Emami Afshar\n",
    "### STD number: 810197662\n",
    "#### Abstract: in this project, we are going to implement a predictor model based on Naive Bayes algorithm to classify comments on a website into two groups, recommended and not recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "import pandas as pd\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./CA3_dataset/comment_train.csv\")\n",
    "test_df = pd.read_csv(\"./CA3_dataset/comment_test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preproccesing\n",
    "\n",
    "### To preprocess datasets we do the following processes:\n",
    "    1- Combining \"title\" and \"comment\" column and create a new column called \"all\".\n",
    "    2- Normalizing data: which will remove semi spaces.\n",
    "    3- Tokenizing each line of dataset to a list of words\n",
    "    4- Lemmatizing each word in the dataset\n",
    "    5- Removing stopwords: we have used hazm stopword list and remove them from our dataset.\n",
    "    \n",
    "### Question No.1:\n",
    "### Lemmatization VS Stemming \n",
    "*Lemmatization* replaces each word with it's root, causing different form of words from the same root such as nouns, verbs, adjectives and etc to act as if they are the same, like changing \"می‌روم\" to \"رفت#رو\". this will increase the accuracy of our model so we have used it.\n",
    "\n",
    "*Stemming* acts the same az lemmatizing witha difference that it tries to remove suffix and prefixes froma word and creating it's root. However hazm Stemizer did not work so accurate and in somecases it detect suffix and prefixes wrongly, like changing \"عالی\" to \"عال\". Stemming part is commented so it wouldn't decrease accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(df):\n",
    "    normalizer = Normalizer()\n",
    "    df[\"all\"] = df.apply(lambda line: normalizer.normalize(line[\"all\"]), axis=1)\n",
    "    return df\n",
    "\n",
    "def Stem(df):\n",
    "    stemmer = Stemmer()\n",
    "    df[\"all\"] = df.apply(lambda line: [stemmer.stem(word) for word in line[\"all\"]], axis=1)\n",
    "    return df\n",
    "\n",
    "def lemmatize(df):\n",
    "    lemmatizer = Lemmatizer()\n",
    "    df[\"all\"] = df.apply(lambda line: [lemmatizer.lemmatize(word) for word in line[\"all\"]], axis=1)\n",
    "    return df\n",
    "\n",
    "def tokenize(df):   \n",
    "    df[\"all\"] = df.apply(lambda line: word_tokenize(line[\"all\"]), axis=1)\n",
    "    return df\n",
    "\n",
    "def remove_stopwords(df):\n",
    "    stopwords = stopwords_list()\n",
    "    df[\"all\"] = df.apply(lambda line: [word for word in line[\"all\"] if word not in stopwords], axis=1)\n",
    "    return df\n",
    "\n",
    "def pre_process(df):\n",
    "    df = df.copy(deep = True)\n",
    "    df[\"all\"] = df[\"title\"]+\" \" +df[\"comment\"]\n",
    "    df = Normalize(df)\n",
    "    df = tokenize(df)\n",
    "#     df = Stem(df)\n",
    "    df = lemmatize(df)\n",
    "    df = remove_stopwords(df)\n",
    "    return df\n",
    "\n",
    "def tokenize_df(df):\n",
    "    df = df.copy(deep = True)\n",
    "    df[\"all\"] = df[\"title\"]+\" \" +df[\"comment\"]\n",
    "    df = tokenize(df)\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question No.2:\n",
    "    1- posterior : the probability to classify a comment as recommended(or not_recommende) with observing a word as evidence. it is calculated as below:\n",
    "\n",
    "$P(recommended|word) = \\dfrac{P(word|recommended) * P(recommended)}{P(word)}$\n",
    "\n",
    "    2- prior: the probability of a message to be classified as recommended or not_recommended without any evidence. it is calculated as below:\n",
    "    \n",
    "$P(recommended) = \\dfrac{number\\_of\\_recommended\\_comments}{all\\_comments}$\n",
    "\n",
    "    3- likelihood: the probability of a word to appear in a recommended(or not_recommende) comment. it is calculated as below:\n",
    "    \n",
    "$P(word|recommended) = \\dfrac{count\\_of\\_word\\_in\\_all\\_recommended\\_comments}{count\\_of\\_all\\_words\\_in\\_recommended\\_comments}$\n",
    "\n",
    "    4- evidence: count of each word repeated in a comment is our evidence.\n",
    "    \n",
    "    \n",
    "### 3.Naive bayes(train and test)\n",
    "after preprocessing data, we start training.\n",
    "\n",
    "to train our data we calculate the frequncy of each word appeared in a recommended(or not_recommended) comment in the train set, then we store it in a dictionary.\n",
    "\n",
    "for each row in our test dataset, we calculate the probability of the row to be classified as recommended and not recommended and compare these two, each of them which is greater will be the predicted lable.\n",
    "\n",
    "the probability of each line to be labled will be calculated based the bayes rule. it will be equal to multiplication of frequencies of evidences in the row.\n",
    "\n",
    "we use liklely hood and evidences to calculate posterior probablity, and because $P(word)$ is the same for both recommend and not_recommend we ignore the division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clac_word_frequency(row,frequencies):\n",
    "    d = dict(Counter(row))\n",
    "    for key,value in d.items():\n",
    "        if key in frequencies.keys():\n",
    "            frequencies[key] += value\n",
    "        else:\n",
    "            frequencies[key] = value\n",
    "    return frequencies\n",
    "def frequency_dict(df):\n",
    "    frequencies = {}\n",
    "    for i in range(df.shape[0]):\n",
    "        frequencies = clac_word_frequency(df.iloc[i][\"all\"],frequencies)\n",
    "    return frequencies\n",
    "        \n",
    "def train(df,recommend):\n",
    "    df = df[df[\"recommend\"] == recommend]\n",
    "    return frequency_dict(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question No.3:\n",
    "in this model we have defiend the probability of each word as it's frequency(number of times the word is repeated). so if our model observes a word which is not in the train set recommended comments it will assume it's probability is zero to be recommended and it will classify it as not_recommended no matter what other words are.\n",
    "\n",
    "### Question No.4:\n",
    "### Additive Smoothing\n",
    "\n",
    "to solve the problem mentioned in question no.3, we use addetive smoothing. in order to implement it, we increase the frequency of all words by 1. in this case if the model observes a word wich is not in the train set recommended, it assumes its frequency to be 1. and by this when we multiply its frequency by other words it wouldn't cause them to be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes_test(train_df,test_df,smoothing = 0):\n",
    "    recom_freqs = train(train_df,\"recommended\")\n",
    "    not_recom_freqs = train(train_df,\"not_recommended\")\n",
    "    \n",
    "    prior_recom = sum(test_df[\"recommend\"] == \"recommended\") / len(test_df)\n",
    "    prior_not_recom = sum(test_df[\"recommend\"] == \"not_recommended\") / len(test_df)\n",
    "    \n",
    "    result = []\n",
    "    for i in range(test_df.shape[0]):\n",
    "        p_recom = prior_recom\n",
    "        p_not_recom = prior_not_recom\n",
    "        for word in test_df[\"all\"].iloc[i]:\n",
    "            if word not in recom_freqs.keys():\n",
    "                recom_freqs[word] = smoothing\n",
    "            else:\n",
    "                p_recom *= (recom_freqs[word] + smoothing)\n",
    "                \n",
    "            if word not in not_recom_freqs.keys():\n",
    "                not_recom_freqs[word] = smoothing\n",
    "            else:\n",
    "                p_not_recom *= (not_recom_freqs[word] + smoothing)\n",
    "                \n",
    "        if p_recom > p_not_recom:\n",
    "            result.append(\"recommended\")\n",
    "        else:\n",
    "            result.append(\"not_recommended\")\n",
    "        \n",
    "    test_df[\"predict\"] = result\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluation\n",
    "\n",
    "### Question No.5:\n",
    "\n",
    "#### Precision:\n",
    "if our model detects only a few comments as recommended and if it detects them correctly, our model precision would be 100% although it is not that good and have misdetected so many rows as not_recommended.\n",
    "\n",
    "#### Recall\n",
    "if our model detects all comments as recommended the recall value would be 100%, however we know our model has misdetects do many not_recommended comments as recommended and it is not as good as 100%.\n",
    "\n",
    "by this statements, precision or recall alone can not be a great measurement of our model.\n",
    "\n",
    "### Question No.6:\n",
    "\n",
    "#### F1\n",
    "\n",
    "The F1 score is the harmonic mean of the precision and recall.The highest possible value of an F-score is 1, indicating perfect precision and recall, and the lowest possible value is 0, if either the precision or the recall is zero. The F1 score kinda combines recall and precision and it's a better score to meausure our model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Accuracy(df):\n",
    "    return sum((df[\"recommend\"] == df[\"predict\"]))/ len(df)\n",
    "\n",
    "def Precision(df):\n",
    "    return sum((df[\"recommend\"] == df[\"predict\"]) & (df[\"predict\"] == \"recommended\"))/ len(df[df[\"predict\"] == \"recommended\"])\n",
    "\n",
    "def Recall(df):\n",
    "    return sum((df[\"recommend\"] == df[\"predict\"]) & (df[\"predict\"] == \"recommended\"))/ len(df[df[\"recommend\"] == \"recommended\"])\n",
    "\n",
    "def F1(df):\n",
    "    return 2*(Precision(df) * Recall(df)) / (Precision(df) + Recall(df))\n",
    "\n",
    "def print_result(df):\n",
    "    print(\"Accuracy: \" + str(Accuracy(df)*100) +\"%\")\n",
    "    print(\"Precision: \" + str(Precision(df)*100) +\"%\")\n",
    "    print(\"Recall: \" + str(Recall(df)*100) +\"%\")\n",
    "    print(\"F1: \" + str(F1(df)*100) +\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question No.7:\n",
    "the results are as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preproccesing and Additive Smoothing\n",
      "Accuracy: 91.875%\n",
      "Precision: 88.50574712643679%\n",
      "Recall: 96.25%\n",
      "F1: 92.21556886227546%\n",
      "\n",
      "Additive Smoothing\n",
      "Accuracy: 88.125%\n",
      "Precision: 83.51648351648352%\n",
      "Recall: 95.0%\n",
      "F1: 88.8888888888889%\n",
      "\n",
      "Preproccesing\n",
      "Accuracy: 89.625%\n",
      "Precision: 87.82816229116945%\n",
      "Recall: 92.0%\n",
      "F1: 89.86568986568987%\n",
      "\n",
      "Using None\n",
      "Accuracy: 87.75%\n",
      "Precision: 83.70535714285714%\n",
      "Recall: 93.75%\n",
      "F1: 88.44339622641509%\n"
     ]
    }
   ],
   "source": [
    "print(\"Preproccesing and Additive Smoothing\")\n",
    "preprocess_train_df = pre_process(train_df)\n",
    "preprocess_test_df = pre_process(test_df)\n",
    "print_result(Naive_Bayes_test(preprocess_train_df,preprocess_test_df,smoothing = 1))\n",
    "\n",
    "print(\"\\nAdditive Smoothing\")\n",
    "train_df_token = tokenize_df(train_df)\n",
    "test_df_token = tokenize_df(test_df)\n",
    "print_result(Naive_Bayes_test(train_df_token,test_df_token,smoothing = 1))\n",
    "\n",
    "print(\"\\nPreproccesing\")\n",
    "preprocess_train_df = pre_process(train_df)\n",
    "preprocess_test_df = pre_process(test_df)\n",
    "print_result(Naive_Bayes_test(preprocess_train_df,preprocess_test_df,smoothing = 0))\n",
    "\n",
    "print(\"\\nUsing None\")\n",
    "train_df_token = tokenize_df(train_df)\n",
    "test_df_token = tokenize_df(test_df)\n",
    "print_result(Naive_Bayes_test(train_df_token,test_df_token,smoothing = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question No.8:\n",
    "according to the results we got in the previous part, it is obvious that using additive smoothing and preprocessing will lead us to a greater accuracy, that's because in this case our model calculates the result based on every word and if a word is not in the train set it will not be able to cause the whole line probability to be zero.\n",
    "\n",
    "as it can be seen both additive smoothing and preprocessing have increased the acuuracy, so we can conclude that we have used a good way to preprocess our data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question No.9:\n",
    "some cases where we have misclassify the comments are printed below.\n",
    "\n",
    "these comments contain positive adjectives with negative verbs or negative adjectives with positive verbes, and we have detect them as recommended because of our preprocessing.\n",
    "in our poreprocessing we convert each verb to its root which in some cases will cause negative and positive verbes to be treated the same. and then our model sees the posistive adjectives and will classify the comment as recommended.\n",
    "another problem is when our preprocessor distingushes the negative verbs from positive ones, but because we have ignored the position of words, the model will be confused observing positive verbs which lead it to classify the comment as recommended and negative adjectives which will cause it to do the opposite. all of this thing can cause our model to misclassify some comments.\n",
    "\n",
    "comment number 2 is wrongly labeled as recommended, and our model has correctly predict that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommend:  not_recommended\n",
      "title:  پاور بانک\n",
      "comment:  باسلام خدمت دوستان  من تعجب میکنم از چیه این تعریف میکنن\r\n",
      "گوشی من سامسونگ اس ۶ هستش ۲۵۵۰ \r\n",
      "حالا ۳.۵ بار شارژ میکنه کنار \r\n",
      "بحثم اینجاست \r\n",
      "۲ساعت نیم میکشه شارژ کامل که واقعا خوب نیست فاجعه هستش \r\n",
      "و مورد دیگه اداپتور من فست هستش تازه با فست قشنگ ۷الی۸ ساعت میکشه شارژ بشه \r\n",
      "چیه این خوبه اخه تعریف میکنید \r\n",
      "نه شکل ظاهر مناسب  نه ابعاد خوب \r\n",
      "دیر شارژ میشه \r\n",
      "شارژ کند انجام میده \r\n",
      "تنها مزیت این گارانتی هستش \r\n",
      "تموم شد رفت\n",
      "\n",
      "recommend:  recommended\n",
      "title:  پیشنهاد نمیدم\n",
      "comment:  من دوسه ماهی هست این کفشدازردیجی گرفتم متاسفانه کیفیت چسب کفی خوب نیست و از جلو بلند شده و اینکه بنداش کیفیت لازم رو نداره و پا داخلش بو میگیره قالباشم دقیق نیست بنظرم ارزش این پول نداره ...\n",
      "\n",
      "recommend:  not_recommended\n",
      "title:  اندرمعایب آچارلوله گیر14اینچ ایران پتک\n",
      "comment:  این آچار لوله گیر خیلی سنگینه،برای کارمداوم وکسانی که دست وبازوی ضعیفی دارند اصلا مناسب نیست.اگرقبل ازخریدبه دست می گرفتم،ازخریدمنصرف می شدم..\n",
      "\n",
      "recommend:  not_recommended\n",
      "title:  کلنیل\n",
      "comment:  این نوعش به درد نمیخوره نوعش که گیاهیه خوبه.من استفاده کردم حس خوبی بهش نداشتم نسبت به نوع دیگه این برند.\n",
      "\n",
      "recommend:  not_recommended\n",
      "title:  ارزش خرید ؟!\n",
      "comment:  - مهمترین ایراد مصرف غیر عادی باتری که در صورت کارکردن عادی ممکنه هر روز نیاز به تعویض باتری داشته باشه و از آنجایی که باتری داخلی ندارد عملا بعد از مدتی بلااستفاده می شود.\r\n",
      "- به خاطر پایین بودن نسخه بلوتوث قطع و وصل شدن و تداخل امواج دارد.\r\n",
      "- دکمه پاور ک\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = Naive_Bayes_test(preprocess_train_df,preprocess_test_df,smoothing = 1)\n",
    "wrong_pred = preprocess_test_df[df[\"predict\"] != df[\"recommend\"]].tail()\n",
    "for i in range(wrong_pred.shape[0]):\n",
    "\n",
    "    print(\"recommend: \",wrong_pred[\"recommend\"].iloc[i])\n",
    "    print(\"title: \",wrong_pred[\"title\"].iloc[i])\n",
    "    print(\"comment: \",wrong_pred[\"comment\"].iloc[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
